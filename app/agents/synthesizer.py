from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from app.state import AgentState
from app.models import FinalReport
import os
from dotenv import load_dotenv

load_dotenv()

class SynthesizerAgent:
    def __init__(self, model_name=None):
        if model_name is None:
            model_name = os.getenv("ANTHROPIC_MODEL", "claude-sonnet-4-5")
        
        self.model_name = model_name
        self.fallback_model = "claude-haiku-4-5"
        
        try:
            self.llm = ChatAnthropic(
                model=model_name,
                anthropic_api_key=os.getenv("ANTHROPIC_API_KEY"),
                temperature=0.5,
                max_tokens=4096
            )
            print(f"[SYNTHESIZER] Using model: {model_name}")
        except Exception as e:
            print(f"[SYNTHESIZER] Model {model_name} failed, falling back to {self.fallback_model}: {e}")
            self.llm = ChatAnthropic(
                model=self.fallback_model,
                anthropic_api_key=os.getenv("ANTHROPIC_API_KEY"),
                temperature=0.5,
                max_tokens=4096
            )
            self.model_name = self.fallback_model
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a rigorous professional research analyst. Your job is to synthesize findings into a report.

EVIDENCE GATE - STRICT RULES:
1. Only claim something as a verified fact if supported by the provided text.
2. For "Competitors" or "Vendors", you MUST adhere to:
   - Include a company ONLY if mentioned in â‰¥2 independent sources OR clearly identified as a vendor in 1 high-trust source (check TRUST_SCORE).
   - If evidence is weak, list them under "Potential/Related Vendors (Need Verification)".
3. CITATIONS ARE MANDATORY. Every claim must list its source URL.
4. If the retrieved content is irrelevant or off-topic, clearly state "Insufficient Evidence" instead of hallucinating.

Structure:
- Executive Summary (High-level insights)
- Key Competitors/Findings (Evidence-backed only)
- Weak/Unverified Signals (If applicable)
- Detailed Comparison (Tables favored)
- Sources List (URLs)"""),
            ("user", "Research Query: {query}\n\nFindings:\n{findings}")
        ])
        
        self.chain = self.prompt | self.llm

    async def synthesize(self, state: AgentState) -> dict:
        logger = state.get('logger')
        
        print(f"--- SYNTHESIZER: Generating report for {len(state['findings'])} findings ---")
        
        if logger:
            logger.log('synthesizer', f"Synthesis started with {len(state['findings'])} findings",
                      payload={'finding_count': len(state['findings'])})
        
        # Check for insufficient evidence
        if not state['findings'] or all(f.relevance_score == 0.0 for f in state['findings']):
            if logger:
                logger.log('synthesizer', 'Insufficient evidence detected', level='warn',
                          payload={'reason': 'no_valid_findings'})
                logger.set_status('insufficient_evidence', 'No valid findings to synthesize')
            
            return {
                "final_report": FinalReport(
                    summary="Insufficient Evidence",
                    findings=[],
                    sources=[],
                    formatted_report="# Insufficient Evidence\n\nNo relevant sources found for this query."
                ),
                "messages": ["Insufficient evidence."]
            }
        
        findings_text = "\n\n".join([f"Source: {f.source_url}\nContent: {f.content}" for f in state['findings']])
        
        if logger:
            logger.log('synthesizer', 'Invoking LLM for synthesis', level='debug',
                      payload={'total_content_length': len(findings_text)})
        
        response = await self.chain.ainvoke({"query": state['query'], "findings": findings_text})
        
        report_content = response.content
        
        if logger:
            logger.log('synthesizer', 'Report generated successfully',
                      payload={'report_length': len(report_content)})
            logger.set_final_report(report_content)
            logger.set_status('success')
        
        final_report = FinalReport(
            summary="Generated by TinyScout",
            findings=state['findings'],
            sources=[f.source_url for f in state['findings']],
            formatted_report=report_content
        )
        
        return {"final_report": final_report, "messages": ["Report synthesized."]}

class UpdateSynthesizer:
    """Specialized synthesizer for monitoring updates."""
    
    def __init__(self, model_name=None):
        if model_name is None:
            model_name = os.getenv("ANTHROPIC_MODEL", "claude-sonnet-4-5")
        
        self.llm = ChatAnthropic(
            model=model_name,
            anthropic_api_key=os.getenv("ANTHROPIC_API_KEY"),
            temperature=0.3, # Lower temp for factual summaries
            max_tokens=4096
        )
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an Intelligence Analyst creating an update briefing.
            
            Your task is to synthesize a set of recent monitoring alerts into a consolidated update report.
            
            GUIDELINES:
            1. Focus on what has CHANGED (new releases, verified events, announcements).
            2. Group related updates together (e.g., "Competitor X", "Regulatory Changes").
            3. IGNORE repetitive or low-value updates. Focus on signal over noise.
            4. If multiple updates refer to the same event, combine them into one strong point.
            5. Use bullet points for readability.
            6. CITATIONS ARE MANDATORY. Use [Source Title](URL) format.
            
            Structure:
            # ðŸš¨ Intelligence Briefing: {topic}
            
            ## âš¡ Key Developments (Top Priority)
            (Major events that require immediate attention)
            
            ## ðŸ“‹ Summary of Updates
            (Grouped by category/company)
            
            ## ðŸ”— Source Reference
            (List of all sources used)
            """),
            ("user", "Topic: {topic}\n\nUpdates:\n{updates}")
        ])
        
        self.chain = self.prompt | self.llm
    
    async def synthesize_updates(self, topic: str, updates: list) -> str:
        """Synthesize a list of ScoutUpdate objects into a report."""
        if not updates:
            return "No updates available to synthesize."
        
        # Format updates for the LLM
        updates_text = ""
        for i, update in enumerate(updates, 1):
            timestamp = update.timestamp.strftime('%Y-%m-%d')
            citations = ", ".join([c.get('url', str(c)) if isinstance(c, dict) else str(c) for c in (update.citations or [])])
            
            updates_text += f"--- UPDATE {i} ({timestamp}) ---\n"
            updates_text += f"HEADLINE: {update.headline}\n"
            updates_text += f"SUMMARY: {update.summary}\n"
            updates_text += f"FULL CONTENT: {update.full_content}\n"
            updates_text += f"SOURCES: {citations}\n\n"
            
        print(f"[UPDATE_SYNTH] Synthesizing {len(updates)} updates for topic: {topic}")
        response = await self.chain.ainvoke({"topic": topic, "updates": updates_text})
        
        return response.content
